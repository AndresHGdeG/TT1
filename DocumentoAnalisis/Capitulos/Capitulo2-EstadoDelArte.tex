
\TChapter{Estado del arte}{beta}
\ \\\\
%-----------------------------------Introducción---------------------------------------------%
\section{Introducción}


El uso de la información digital ha superado la producción de libros y publicaciones impresas, este fenómeno ha influenciado la producción de bibliotecas digitales, publicaciones electrónicas; Se ha incrementado el uso de las redes sociales, correos electrónicos, creando un gran repositorio de información útil, el cual puede ser analizado\cite{machine}.\\

Debido a la necesidad de procesar grandes volúmenes de datos recolectados de Internet, se han desarrollado diversas investigaciones entorno a esta tarea. A continuación se muestran distintos artículos nacionales e internacionales relacionados al campo de investigación (Clasificación de noticias), de igual forma se muestran herramientas web que desempeñan un trabajo similar al propuesto (Sitio web de noticias). Cabe destacar que el área de interés cuenta con un amplio desarrollo, no obstante solo se mencionan los trabajos más relevantes para este documento.

%-------------------------------Trabajos nacionales-----------------------------------------%

\section{Trabajos nacionales}

\begin{large}
	 \textbf{Clasificación de noticias de diarios de circulación nacional mediante aprendizaje automático }\\
\end{large}


Este trabajo terminal clasifica mediante técnicas de aprendizaje automático, noticias
de diarios de circulación nacional en las diferentes secciones en que en estos se dividen. Se recolectaron 4,027 artículos de tres diarios de circulación nacional: \textbf{El universal}, \textbf{La jornada} y \textbf{Excélsior}. 3,624 noticias fueron utilizadas para la etapa de entrenamiento y 407 para hacer las pruebas. Los algoritmos implementados fueron los siguientes: \\


\textbf{Selección de características}

\begin{itemize}
	
	\item Frecuencia
	\item Binarización
	\item TF-IDF
\end{itemize}

\textbf{Clasificación}

\begin{itemize}
	\item Árboles de decisión
	\item Máquinas de soporte vectorial
	\item Naive Bayes Multinomial
	\item Regresión logística
\end{itemize}

El trabajo utiliza  pre-procesamiento de la información con la técnica tokenización y lematización. Los resultados mostraron que implementar el algoritmo TF-IDF con máquinas de soporte vectorial se obtiene el mejor resultado con un 79.81\% de exactitud, 8 de cada 10 noticias son clasificadas correctamente a la sección que pertenecen.\\

\begin{large}
	 \textbf{Clasificación automática de textos de desastres naturales en México}\\
\end{large}

En este trabajo se propone clasificar noticias del ámbito desastres naturales utilizando estrategias de reducción de dimensionalidad conocidas como umbral en la frecuencia y ganancia en la información, los métodos de clasificación utilizados fueron el clasificador simple de Bayes y vecinos más cercanos.\\

Se utilizaron 375 noticias del periódico Reforma como conjunto de entrenamiento, para posteriormente clasificarlas (relevantes e irrelevantes), de los cuales 11.5\% de noticias eran relevantes y el 88.5\% restante eran irrelevantes. Una vez obtenido el conjunto de noticias se procedió con un pre-procesamiento, el cual reducía el tamaño de los documentos, eliminando la parte de los textos que no se consideraban relevantes, posteriormente se realizó el indexado, el cual los documentos son representados por vectores de palabras en un espaso de dimensionalidad n, lo cual permite una reducción de dimensionalidad, finalmente se utilizaron técnicas de clasificación (Algoritmo simple de Bayes) con el cual se obtuvo un resultado de 97\% de efectividad al clasificar las noticias de desastres naturales\cite{cuatro}.\\

\begin{large}
	 \textbf{News article classification of mexican newspapers}\\
\end{large}

En este trabajo se propone la clasificación de noticias utilizando métodos supervisados de Machine Learning para su clasificación

Para realizar esta tarea se recolectaron 4,027 artículos junto con su sección correspondiente de tres periódicos mexicanos duranta un periodo de 6 meses. Diferentes caracteristicas fueron extraidas y un conjunto de métodos de aprendizaje fueron probados. Los resultados obtenidos muestran una exactitud de 80\% en la clasificación de los artículos en su correspondiente sección de los tres periódicos seleccionados\cite{cinco}.\\


%------------------------------Trabajos internacionales--------------------------------------%

\section[Trabajos i.]{Trabajos internacionales}


\begin{large}
	 \textbf{Clasificador de noticias usando autoencoders}\\
\end{large}

En este trabajo se propone la clasificación de noticias utilizando Deep Learning, las noticias se clasificaron en las siguientes categorias:

\begin{itemize}
	\item Deportes
	\item Política
	\item Espectáculos
	\item Economía
	\item Policía
\end{itemize}
El alcance que tiene es:
\begin{itemize}
	\item Local (Valpara iso)
	\item Nacional (Chile)
	\item Internacional (Resto del mundo)
\end{itemize}
El clasificador se constuyó utilizando una base de datos con 542 noticias etiquetadas con los criterios anteiores, las características se obtuvieron utilizando Autoencoders (AE) para entrenar una Red Neuronal Artificial (ANN).
Los resultados obtenidos con 156 noticias fue una tasa de éxito del 92.3\% para la clasificación de la categoría y un 87.2\% para el clasificador de alcance.
La tasa general de éxito, categoría y alcance fue de 83.75\% \cite{seis}.\\

\begin{large}
	 \textbf{Document classification for newspaper articles}\\
\end{large}

En este trabajo se enfocaron en clasificar articulos del MIT (Massachusetts Institute of Technology) de las siguientes categorías:

	\begin{itemize}
		\item Arts
		\item Features
		\item News
		\item Opinion
		\item Sports
		\item World
	\end{itemize}
Para los cuales utilizarón el algoritmos de clasificación como el Naive Bayes ya que era uno de los clasificadores más simples y eficaces que otras técnicas de clasificación, de igual manera utilizarón la clasificación máxima de entropia el cual provee segmentación de texto, modelado de lenguaje.
Se utilizarón un corpus 3000 artículos en total, siendo 500 artículos de cada sección mencionada, para el entrenamiento se utilizarón 120 artículos siendo 20 de cada sección y teniendo como resultado un 77\% de exactitud\cite{siete}.\\

\begin{large}
	 \textbf{Categorization of web news documents using word2vec and deep learning}\\
\end{large}

El trabajo desarrolla un algoritmo utilizando \textit{Word2Vec} como entrada a una red neuronal profunda, para clasificar noticias en 6 categorías:

\begin{itemize}
 
 	\item \textit{Entertainment} 
 	\item \textit{Sports}
 	\item \textit{The economy}
 	\item \textit{It, science}
 	\item \textit{Domestic} 
 	\item \textit{Overseas}

\end{itemize}

 En el análisis se ha utilizado textos redactados en lenguaje japones obtenidos de sitios web como Yahoo. Se ha utilizado 600 noticias para el entrenamiento de la red y 200 para realizar pruebas. La \textbf{Tabla 1} muestra el resultado obtenido, además se ha probado el algoritmo \textit{Naive bayes} para tener un punto de comparación con base al tiempo y exactitud de clasificación.\\

\begin{tabular}{|l|l|l|l|l|}
\hline

\multicolumn{5}{| >{\columncolor{black}}c|}{ \textcolor{myWhite}{\textbf{Tabla 1}}}\\
\hline
Algoritmo&Tiempo 1[s]&Tiempo 2[s]& Tiempo 3[s]&Exactitud[\%] \\
\hline
Propuesto & 1353.34& 1390.63& 1367.92 & 78\\ 
\hline
Naive bayes&4.97& 5.10& 4.97&68\\

\hline
\end{tabular}
\ \\\\\\
Los resultados arrojados muestran que el método propuesto obtiene una mayor exactitud de clasificación con un 78\%, 10 puntos porcentuales superior a \textit{Naive bayes} con 68\%, sin embargo este último ocupa solo 5 segundos para completar el proceso superando por mucho la propuesta del artículo el cual ocupa 1350 segundos.\cite{C2:T.Inter:Word2v}\\

\begin{large}
	 \textbf{Category classification and topic discovery of japanese and english news articles}\\
\end{large}


Este trabajo presenta algoritmos para la clasificación de noticias en categorías (Como política, deportes, tecnología) y temas (Sección de deportes: tenis, fútbol, golf), además se especializa en descubrir y clasificar temas emergentes en la Internet. Se ocupa un método pare extraer palabras claves en cualquier idioma propuesto por Bracewell \cite{C2:T.Inter:Bracewell} que tenga herramientas de análisis morfológico. Se definieron 8 secciones posibles a las que puede ser clasificado el artículo proporcionado, las cuales son: 
\begin{itemize}

	\item \textit{Business} 
	\item \textit{Politics} 
	\item \textit{Crime and Misfortune} 
	\item \textit{Health} 
	\item \textit{Sports} 
	\item \textit{Entertainment} 
	\item \textit{Technology} y 
	\item \textit{Science and Nature}

\end{itemize}

Para el desarrollo del método se ocuparon 1,000 artículos descargados de sitios como Yahoo, se recolectaron noticias redactadas en lenguaje inglés y japones. 800 se ocuparon en el entrenamiento y 200 para realizar pruebas. Los algoritmos probados fueron : \textbf{Naive bayes}, \textbf{Árboles de decisión}, \textbf{Máxima entropia} y el propuesto por este trabajo. La tabla 2 muestra los resultados obtenidos contemplando la precisión, exhaustividad y la media-F : \\

\begin{tabular}{|l|l|l|l|}
\hline

\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Algoritmo}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Exhaustividad}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Precisión}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Media-F}}}\\
\hline

Naive bayes&54.3\%& 69.3\%&55.2\%\\
\hline
Árboles de decisión&60.2\%&60.3\%&57.2\%\\
\hline
Máxima entropia&15.3\%&14.8\%&12.1\%\\
\hline
Propuesta&63.4\%&68.6\%&65.9\%\\

\hline

\end{tabular}
\ \\\\\\
Los algoritmos presentados en este documento se basaron en una extracción de palabras clave
que es capaz de manejar múltiples idiomas y no requiere una colección de documentos o estadísticas del corpus.\\




\begin{large}
	 \textbf{Automatic news articles classification in indonesian language by using naive bayes classifier method}
	 \\
\end{large}

El artículo clasifica noticias ocupando el algoritmo clásico \textit{Naive Bayes}. El método propuesto consiste en 3 tareas importantes: Pre-procesamiento el cual consiste en la siguiente serie de pasos: 
 
\begin{itemize}

	\item \textit{Case folding}: Proceso para convertir todas letras en minúsculas
	\item \textit{Parsing}: Es el proceso de convertir oraciones en palabras
	\item \textit{Stopwords elimination}: Es el proceso de eliminar palabras que se repiten con mucha frecuencia y no es información útil (Una definición mas amplia se da en el capítulo 3)
	\item \textit{Stemming}: Es un proceso de corte o eliminación de afijos en una palabra. Las variantes de los afijos son prefijos, sufijos, in-fijos y con-fijos (la combinación de prefijos y sufijos)

\end{itemize}	

La segunda tarea es la etapa de entrenamiento del algoritmo y por último la clasificación de artículos. Cabe destacar que el método \textbf{Frecuencia de término} (Frecuencia de aparición de una palabra en un documento dado) es utilizado en la etapa de aprendizaje. Las secciones definidas en el trabajo son: \textit{Economy}, \textit{Sport}, \textit{Tecnology}, \textit{Healt} y \textit{Metropolitan}. Para el proceso de aprendizaje se ocuparon 50 noticias por tópico, las cuales fueron recolectadas de los sitios web \textit{Kompas}\footnote{Sitio web Indu de noticias: https://www.kompas.com}, \textit{Republika}\footnote{Sitio ya no disponible: http://www.republika.com} y \textit{Suara pembaruan}\footnote{Sitio web Indu: https://sp.beritasatu.com}.Las pruebas fueron realizadas con 12 noticias por sección. Además para tener una métrica en la eficiencia del método se calculó la precisión, exhaustividad y la media-F. Los resultados se muestran en  la siguiente tabla (En la columna \textbf{Documentos} se coloca el número de noticias usadas para la prueba):\\


\begin{tabular}{|l|l|l|l|}
\hline

\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Documentos}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Exhaustividad}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Precisión}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Media-F}}}\\
\hline

12&90\%&90\%&90\%\\
\hline
24&93.4\%&91.3\%&92.33\%\\
\hline
36&93.75\%&90.9\%&92.30\%\\
\hline
48&93.1\%&93.1\%&93.1\%\\
\hline
60&94.11\%&90.5\%&92.26\%\\

\hline
\end{tabular}
\ \\\\\\
Los resultados muestran que el método de \textbf{Naive bayes} es un clasificador con una exactitud alta en todos las categorías dadas.\\


\begin{large}
	 \textbf{News article text classification in indonesian language}
	 \\
\end{large}

Este documento busca el mejor algoritmo de clasificación en lenguaje Indu, comparando la eficiencia de algoritmos de selección de características (Palabras clave) y de clasificación de noticias. Las secciones definidas por el artículo son las siguientes, \textit{Economy}, \textit{Health}, \textit{Sports}, \textit{Politic} y \textit{Tecnology}; El trabajo realiza pre-procesamiento de datos con  los métodos \textit{lemmatization} y \textit{Stopwords} para reducir el ruido en la información. Para la obtención de noticias se hace uzo de la técnica \textit{crawling}\footnote{Extracción de información en la web} en el sito \textit{ccnnindonesia}\footnote{Sitio web de noticias: wwww.ccnnindonesia.com}. Se obtuvieron 1,000 artículos para cada sección. 800 se usaron para la etapa de entrenamiento y 200 para realizar pruebas. Se muestra la lista de los algoritmos implementados:

\begin{itemize}
	\item Selección de características
	\begin{itemize}
		\item \textbf{Singular Value Decomposition}(SVD)
		\item \textbf{Term frequency-inverse document frequency}(TF-IDF)
	\end{itemize}

	\item Clasificación
	\begin{itemize}
		\item \textbf{Support vector machine}(SVM)
		\item \textbf{Naive bayes classifier}(NBC)
		\item \textbf{Gaussean naive bayes}(GNB)
		\item \textbf{Multinominal naive bayes}(MNB) 
		\item \textbf{Multivariate naive bayes}(MNB)
		\item \textbf{Bernulli naive bayes}(BNB)
	\end{itemize}
\end{itemize}


Los resultados obtenidos se muestran en la siguiente tabla:\\

\begin{tabular}{|l|l|l|l|}
\hline

\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Combinación usada}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Precisión}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Exhaustividad}}}&\multicolumn{1}{| >{\columncolor{black}}l|}{ \textcolor{myWhite}{\textbf{Tiempo (Segundos)}}}\\
\hline

TFIDF + GNB&-&-&-\\
\hline
TFIDF + BNB&0.9822558&0.9820000&0.7015419\\
\hline
\textbf{TFIDF + MNB}&\textbf{0.9841519}&\textbf{0.9840000}&\textbf{0.7020838}\\
\hline
TFIDF + SVM&0.9794023&0.9790000&74.9765017\\
\hline
TFIDF + SVD + GNB&0.3591179&0.3460000&11.4571054\\
\hline
TFIDF + SVD + BNB&0.3925421&0.3050000&11.8058102\\
\hline
TFIDF + SVD + MNB&-&-&-\\
\hline
TFIDF + SVD + SVM&0.4360882&0.3910000&1.3520746\\
\hline

\end{tabular}
\ \\\\

La tabla muestra que el mejor resultado es en combinación de TF-IDF y  \textit{Multinominal naive bayes}(MNB) con la precisión y exhaustividad mas alta el cual está alrededor de 98.4\% con un tiempo de 0.702 segundos, seguido de TF-IDF y \textit{Bernulli naive bayes}(BNB)  con 98.2\% en precisión y exhaustividad con un tiempo de .701 segundos.


%------------------------------Herramientas Disponibles-------------------------------------%

\section[Herramientas d.]{Herramientas disponibles}


Entre las herramientas de trabajo que son de utilidad para el procesamiento de lenguaje natural y aprendizaje automático se encuentran:\\

\begin{large}
	 \textbf{Cloud Natural Language}\\
\end{large} 

Google Cloud Natural Language \cite{ocho} revela la estructura y el significado del texto con modelos potentes de aprendizaje automático previamente entrenados en una API de REST fácil de usar y con modelos personalizados se puede utilizar para extraer información sobre personas, lugares, eventos y muchos otros datos, que se mencionan en documentos de texto, artículos periodísticos o entradas de blog. También se puede utilizar para comprender las opiniones sobre los productos expresadas en los medios sociales o analizar la intención en las conversaciones de los clientes que se den en un centro de atención telefónica o una aplicación de mensajería.\\

\begin{large}
	 \textbf{Googlebot}\\
\end{large}

Es el crawler diseñado por Google para indexar el contenido nuevo o actualizado de Internet.
Googlebot\cite{nueve} no sólo tiene la capacidad de rastrear e indexar los sitios web de Internet, sino que además puede extraer información de ficheros como pueden ser PDF, XLS, DOC, etc.
Una vez el contenido está indexado, el servidor lo clasifica y establece un orden de relevancia para las distintas búsquedas que pueda efectuar un usuario, es decir, lo posiciona.\\



\begin{large}
	 \textbf{Watson natural language classifier}\\
\end{large}

Watson NLC \cite{diez} aplica técnicas de computación cognitiva para analizar un texto y proporcionar la clase que mejor encaja entre un conjunto de clases predefinidas a partir de un texto corto.
Al ser un clasificador, esta compuesto de ciertos pasos, en primera instancia se necesitan de clases las cuales son etiquetas que identificarán el texto analizado y será la salida proporcionada por el clasificador; posteriormente se debe tomar en cuenta que se necesita de una colección de textos, los cuales proporcionarán apoyo para que el clasificador logre identificar las clases ingresadas posteriormente teniendo todos estos datos se logra entrenar al clasificador, el cual proporcionará una salida dependiendo a los datos que fueron utilizados.


