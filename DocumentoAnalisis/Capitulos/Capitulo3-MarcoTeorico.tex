
\chapter{Marco teórico}

En esta sección se expondrán de manera detallada conceptos los cuales son esenciales para la elaboración de este trabajo


\section{Crawler}
Un crawler [11] es una herramienta la cual analiza sitios web, permitiendo recolectar las páginas web para así posteriormente extraer la información que contengan. Un crawler también conocido como como robot o spider, es un sistema para la descarga masiva de páginas web. Son uno de los componentes principales de los motores de búsqueda web, los sistemas que reúnen un conjunto de páginas web, las indexan y permiten a los usuarios realizar consultas contra el índice y encontrar las páginas web que coincidan con las consultas.


\section{Sitios web}
Un sitio web es un conjunto de páginas web

\section{Página web}
Una página web es un documento electrónico el cual forma parte de la WWWW (\textit{World Wide Web}) generalmente construido en el lenguaje HTML (Hyper Text Markup Language). Este documento puede contener enlaces que nos direcciona a otra página web. Para visualizar una página web es necesario de un browser o un navegador[12]. Dentro de las páginas web podemos encontrar un sinfin de sitios los cuales pueden ser de nuestro interés.

\section{Blog}
Un blog es una página web en la cual el usuario no necesita conocimientos específicos del medio electrónico ni del formato digital para poder aportar contenidos de forma inmediata, ágil y constante desde cualquier punto de conexión a Internet [13]. En un blog el usuario puede compartir cualquier tipo de información que sea de su agrado, teniendo una mayor libertad de expresión lo cual permite que otras personas compartan y comenten su manera de expresarse.


\section{Foro}
Un foro es una herramienta de comunicación asíncrona. Los  foros permiten la comunicación de los participantes desde cualquier lugar en el que  esté  disponible  una  conexión  a Internet  sin  que  éstos  tengan  que  estar dentro del sistema al mismo tiempo, de ahí su naturaleza asíncrona [14]. Brindando una mayor interacción entre distintos participantes y permitiendo conocer la opinión sobre un tema de distintas personas.


\section{Lenguaje}
El lenguaje es un medio de comunicación a traves de de un sistema de símbolos[15].
La Real Academía Española define al lenguaje como la facultad del ser humano de expresarse y comunicarse con los demás a través del sonido articulado o de otros sistemas de signos.

\section{Procesamiento de lenguaje natural}
El procesamiento de lenguaje natural es una disciplina de la Inteligencia Artificial que se ocupa de la formulación e investigación de mecanismos computacionales para la comunicación entre persoonas y maquinas mediante el uso de Lenguajes Naturales[16].

\section{Tokenización}


Es la acción de separar el texto en sus unidades míninas(Palabras), se les
asigna un código como el asiic o hexadecimal para ser reconocidas de fórma
única, son almacenas para su postrior análisis y reconocimiento. Cabe mencionar que los
signos de puntuación son eliminados.

\section{Lematización}

Es el proceso lingüstico que, dada una palabra flexionada se encuentra su
lema. Una palabra flexionada es cuando esta en el plural, en femenino conjugada,
diminutivo o en superlativo. El lema es la palabra que esta en singular para
sustantivo, singular masculino para adjetivo e infinitivo para un verbo. Ejemplo:

	\begin{itemize}
		\item amigos, amiga, amiguitos-> Amigo
		\item soy, son, es->Ser
	\end{itemize}

Cabe mencionar que existen diversos grados de lemataizaicón

	\begin{itemize}
		\item Mórfólogica: Es la anterior mente explicada
		\item Sintáctica: Toma encuenta el contexto donde se encuentra la palabra

	\end{itemize}

Una opción para lematizar es Freeling, este es un lematizador hecho por la
universidad de catalunia.

\section{Representación del texto}
Los métodos de aprendizaje automático, requieren que la información este
representado en un formato que facilite su procesamiento. Un método utilzado
es representar los datos en un vector de valores numéricos.

\section{Corpus}
Se le llama corpues a la recopilación de un conjunto de textos, de materiales escritos y/o hablados, agrupados bajo un conjunto de criterios mínimos, para realizar ciertos análisis lingüísticos.


\section{Algoritmos de clasificación}


\subsection{Naive bayes}
Es una aproximación probabilistica, las cuales hacen especualiciones sobre
como deben ser generados los datos. Generalmente utiliza aprendizaje superbisado sobre el conjuto de entrenamiento para estimar sus parámetros. Con el conjunto de entrada se aplica el teorema de bayes.

\subsection{Maquina de soporte vectorial}
Las maquinas de soporte vectorial son sistemas de aprendizaje los cuales
se basan en el uso de un espacio de funciones lineales, el cual se encuentra con
mas dimenciones inducido por un kernel, en el que las hipotesis son las entradas
para el algoritmo.
El algoritmo induce separadores lineales ya sea en el espacio original de los
ejemplos de entrada, si los datos no son separabales se busca un hiperplano en
el que si lo sean, se hace de forna implicita con las funciones kernel.